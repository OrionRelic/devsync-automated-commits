import numpy as np
from itertools import combinations

def most_similar(embeddings):
    """
    Find the pair of phrases with the highest cosine similarity.
    
    Args:
        embeddings: Dictionary with phrases as keys and their embedding vectors as values
        
    Returns:
        Tuple of the two most similar phrases
    """
    phrases = list(embeddings.keys())
    
    # Calculate cosine similarity for all pairs
    max_similarity = -1
    most_similar_pair = None
    
    # Iterate through all unique pairs
    for phrase1, phrase2 in combinations(phrases, 2):
        # Get embedding vectors
        vec1 = np.array(embeddings[phrase1])
        vec2 = np.array(embeddings[phrase2])
        
        # Calculate cosine similarity
        # cosine_similarity = dot_product / (norm1 * norm2)
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        cosine_similarity = dot_product / (norm1 * norm2)
        
        # Update if this is the highest similarity found
        if cosine_similarity > max_similarity:
            max_similarity = cosine_similarity
            most_similar_pair = (phrase1, phrase2)
    
    print(f"Most similar pair has cosine similarity: {max_similarity:.6f}")
    return most_similar_pair


# Test with the provided embeddings
embeddings = {
    "The discount offered was enticing.": [-0.12655314803123474,-0.0466570146381855,-0.27802109718322754,0.03967156261205673,0.13155940175056458,0.05116845667362213,-0.15833696722984314,0.4144703149795532,-0.007458427920937538,-0.06921420991420746,0.13062800467014313,-0.044503167271614075,-0.13924339413642883,-0.1716093271970749,0.2568318843841553,0.13225793838500977,0.009481299668550491,-0.024609174579381943,-0.1264367252588272,0.16066545248031616,0.01923910528421402,0.10082339495420456,-0.02124742418527603,-0.02405615895986557,-0.15007084608078003,-0.19244927167892456,-0.2273765504360199,-0.2924576997756958,0.13807915151119232,-0.05678592622280121,0.03731397166848183,-0.12795023620128632,-0.050906501710414886,-0.10140551626682281,-0.08929739147424698,0.2691728472709656,-0.06770069897174835,0.07241588085889816,0.13260720670223236,-0.12201260775327682,0.01567361317574978,-0.158919095993042,0.1357506662607193,0.07381296902894974,0.01432018168270588,0.15472781658172607,0.0062141441740095615,-0.08859884738922119,0.01254471205174923,0.14797520637512207],
    "I love the variety of products available.": [0.1263255476951599,-0.3116876780986786,-0.1845686137676239,0.14346520602703094,0.025372233241796494,-0.2828041911125183,0.09950517863035202,0.23424185812473297,-0.03733427822589874,0.0246580820530653,0.15838304162025452,-0.19409063458442688,-0.16615936160087585,0.07708873599767685,0.03473556041717529,-0.08458733558654785,-0.18012499809265137,0.1893296241760254,-0.09109405428171158,0.08065950125455856,0.08831679821014404,0.04641987755894661,-0.13743458688259125,-0.18075980246067047,-0.01637590117752552,-0.14092598855495453,-0.23630495369434357,0.06447205692529678,0.07486693561077118,-0.08181007951498032,0.06530523300170898,-0.21678480505943298,-0.06542425602674484,0.021603098139166832,0.005911591462790966,0.1277538537979126,-0.004547759424895048,0.05074446648359299,0.32470110058784485,-0.08546018600463867,-0.04284911975264549,0.07546205818653107,0.202660471200943,-0.08553953468799591,0.00024378496163990349,-0.03582662343978882,-0.29058051109313965,-0.08950705081224442,0.03743346780538559,-0.06633678823709488],
    "I found it hard to navigate the website.": [0.05301663279533386,-0.21206653118133545,-0.3240986168384552,-0.03143302723765373,0.12086819857358932,-0.12435400485992432,-0.1547534465789795,-0.07344505935907364,-0.16026587784290314,0.12265162914991379,-0.12467826157808304,-0.12411080300807953,-0.04150537773966789,0.026143522933125496,0.12581317126750946,0.0643252283334732,-0.0636361762881279,-0.08297022432088852,-0.2712441384792328,0.0668787807226181,0.23184643685817719,-0.03439190611243248,0.02334677428007126,0.07883589714765549,-0.07770098745822906,0.026042193174362183,-0.007098270580172539,0.09103620797395706,0.17801915109157562,0.051192667335271835,0.051760122179985046,-0.17737063765525818,0.16164399683475494,0.016608230769634247,-0.06947287172079086,-0.20606771111488342,0.13554099202156067,0.22228075563907623,0.19893397390842438,0.0876314714550972,0.03603347763419151,0.3054536283016205,0.34631049633026123,0.008765174075961113,-0.053057167679071426,0.09346816688776016,-0.18855763971805573,-0.05759681761264801,-0.03198021650314331,0.061325814574956894],
    "Packaging was excellent.": [-0.01674579456448555,-0.06481242924928665,-0.24050545692443848,0.042519159615039825,0.14857585728168488,-0.11343036592006683,0.1299005150794983,0.17366009950637817,-0.12356054037809372,0.049548257142305374,0.23058201372623444,-0.015152188017964363,-0.06047092750668526,-0.08428027480840683,0.140513077378273,0.0330953411757946,0.15987755358219147,-0.13982394337654114,-0.1899235099554062,0.0849694088101387,0.10901995003223419,0.023171907290816307,0.1423737108707428,-0.010603947564959526,-0.12362945079803467,-0.02598010189831257,0.04410415142774582,-0.0650191679596901,0.13754981756210327,0.06319297850131989,0.2340276539325714,-0.1448545753955841,0.5634305477142334,0.003012778703123331,-0.15422670543193817,-0.10137064009904861,0.10013020783662796,0.05392421782016754,0.10895103961229324,-0.017710573971271515,-0.0018617206951603293,0.01796899549663067,0.0550268217921257,0.251669317483902,-0.005680993665009737,0.12080402672290802,-0.08173050731420517,0.1045406237244606,0.040589600801467896,0.1787596344947815],
    "Fast shipping and great service.": [-0.1079404279589653,0.020684150978922844,-0.30074435472488403,0.11729881167411804,0.13952496647834778,-0.018052106723189354,-0.21843314170837402,0.13527116179466248,-0.09257353842258453,-0.09384968131780624,0.11293865740299225,-0.03900212049484253,-0.059287477284669876,-0.1008152961730957,-0.019155437126755714,-0.007078605704009533,-0.02967032417654991,0.03711449354887009,-0.18302017450332642,0.20056714117527008,0.09076566994190216,0.02584189549088478,0.0943814069032669,-0.03799184039235115,-0.25246360898017883,-0.1235731765627861,0.028952494263648987,-0.309251993894577,0.021375395357608795,-0.22204887866973877,0.2159872055053711,-0.11921302229166031,0.21928390860557556,-0.11432114243507385,0.017453914508223534,0.10065577924251556,-0.04200637340545654,0.17493793368339539,0.1322934925556183,0.17025874555110931,-0.15271177887916565,0.004682514350861311,0.2531017065048218,0.11580997705459595,0.014688937924802303,-0.11176885664463043,-0.292662113904953,-0.0397731214761734,0.13729171454906464,0.027570005506277084]
}

# Find and print the most similar pair
result = most_similar(embeddings)
print(f"\nMost similar pair:")
print(f"  1. {result[0]}")
print(f"  2. {result[1]}")
